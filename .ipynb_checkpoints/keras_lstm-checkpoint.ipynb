{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Keras provides an easy-to-use framework for training Neural Networks\n",
    "\n",
    "This Notebook has **5** sections:\n",
    "\n",
    "1. Introduction\n",
    "2. Function import\n",
    "3. Text loading\n",
    "4. Text encoding\n",
    "5. LSTM model spec\n",
    "    5.1 \n",
    "6. \n",
    "\n",
    "# Overview\n",
    "\n",
    "With this model we aim to predict the next character in a sequence, using a 30-character long sequence as input values\n",
    "\n",
    "# Other avenues to investigate\n",
    "\n",
    "1. Batch learning\n",
    "2. Stochastic learning\n",
    "3. Using Ngrams\n",
    "4. One-hot encoding for the input sequences (as opposed to scaled)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# https://machinelearningmastery.com/text-generation-lstm-recurrent-neural-networks-python-keras/\n",
    "\n",
    "# This Notebook has x sections\n",
    "    # 0. Description\n",
    "    # 1. Function import\n",
    "    # 2. Text loading\n",
    "    # 3. Text encoding\n",
    "    # 4. LSTM model specification\n",
    "    # 5. \n",
    "%matplotlib inline\n",
    "    \n",
    "import numpy as np\n",
    "import sys\n",
    "import keras\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text has 41 unique characters and 134984 total characters.\n"
     ]
    }
   ],
   "source": [
    "# Load text, convert to lowerecase\n",
    "filename = \"oldman.txt\"\n",
    "text = open(filename).read().lower()\n",
    "\n",
    "# mapping of unique characers to integers, and \n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "char_to_int = dict((ch, i) for i, ch in enumerate(chars))\n",
    "int_to_char = dict((i, ch) for i,ch in enumerate(chars))\n",
    "\n",
    "# exploratory statistics\n",
    "\n",
    "text_size = len(text)\n",
    "vocab_size = len(chars)\n",
    "\n",
    "print \"The text has\", vocab_size, \"unique characters and\", text_size, \"total characters.\"\n",
    "\n",
    "# Note \n",
    "\n",
    "# The text has 61 unique characters - that is more than 2x the number of characters in the alphabet\n",
    "# Appropriate encoding will be required for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  134884 in total. This is 100 (input sequence length) less than the total numer of characters.\n"
     ]
    }
   ],
   "source": [
    "# Prepare data and one-hot encode\n",
    "\n",
    "# The length of the input sequence is arbitrary, using the same as \n",
    "# https://github.com/deep-learning-indaba/practicals2017/blob/master/NEW_PRAC_4.ipynb\n",
    "\n",
    "seq_length = 100\n",
    "input_data = []\n",
    "output_data = []\n",
    "\n",
    "#\n",
    "\n",
    "for i in range(0, text_size - seq_length, 1):\n",
    "    input_seq = text[i:i + seq_length]\n",
    "    output_seq = text[i + seq_length]\n",
    "    input_data.append([char_to_int[char] for char in input_seq])\n",
    "    output_data.append(char_to_int[output_seq])\n",
    "    \n",
    "patterns = len(input_data)\n",
    "\n",
    "print \"There are \", patterns, \"in total. This is\", seq_length, \"(input sequence length) less than the total numer of characters.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 1\n"
     ]
    }
   ],
   "source": [
    "# Scaling Input Vector and One-hot Encoding Output Vectors\n",
    "\n",
    "# reshape X to be [samples, time steps, features]\n",
    "X = np.reshape(input_data, (patterns, seq_length, 1))\n",
    "\n",
    "\n",
    "# Input vector scaling\n",
    "\n",
    "X = X / float(vocab_size)\n",
    "\n",
    "# one hot encode the output variable\n",
    "y = np_utils.to_categorical(output_data)\n",
    "\n",
    "print X.shape[1], X.shape[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the LSTM model\n",
    "\n",
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "history = LossHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    }
   ],
   "source": [
    "print y.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the checkpoint\n",
    "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.9896309, 2.9841356, 3.0844753, 3.0505126, 3.0852664, 3.0583553]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1462b1690>]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFwoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x146222e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#model.fit(X, y, epochs=8, batch_size=128, callbacks=[callbacks_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\" n.  then it started out and the old\n",
      "man knelt down and let it go grudgingly back into the dark water \"\n",
      " and the old man was soe tii fas sooel the siark of the siark of the siark of the siark of the siark of the siark of the siark of the siark of t"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-249c3734ffbf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m# Use model to predict which character is most likely next.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m# Assign most probable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/fhl/anaconda2/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1023\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m         return self.model.predict(x, batch_size=batch_size, verbose=verbose,\n\u001b[0;32m-> 1025\u001b[0;31m                                   steps=steps)\n\u001b[0m\u001b[1;32m   1026\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/fhl/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1833\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1834\u001b[0m         return self._predict_loop(f, ins, batch_size=batch_size,\n\u001b[0;32m-> 1835\u001b[0;31m                                   verbose=verbose, steps=steps)\n\u001b[0m\u001b[1;32m   1836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1837\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m/Users/fhl/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_predict_loop\u001b[0;34m(self, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1328\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1330\u001b[0;31m                 \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1331\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1332\u001b[0m                     \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/fhl/anaconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2478\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2479\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/fhl/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/fhl/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/fhl/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/fhl/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/fhl/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Generating Text with an LSTM Network\n",
    "\n",
    "# Load previouly generated network weights\n",
    "filename = 'weights-improvement-08-2.2033.hdf5'\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "# Random Seed\n",
    "start = np.random.randint(0, len(input_data)-1)\n",
    "pattern = input_data[start]\n",
    "print \"Seed:\"\n",
    "print \"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\"\n",
    "\n",
    "# generate characters\n",
    "for i in range(1000):\n",
    "    \n",
    "    #Reshape input\n",
    "    \n",
    "    x = np.reshape(pattern, (1, len(pattern), 1))\n",
    "    \n",
    "    # Scale input\n",
    "    \n",
    "    x = x / float(vocab_size)\n",
    "    \n",
    "    # Use model to predict which character is most likely next. \n",
    "    \n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    \n",
    "    # Assign most probable prediction to index\n",
    "    \n",
    "    index = np.argmax(prediction)\n",
    "    \n",
    "    # Decoded the number to it's alphabetical equivalent\n",
    "    \n",
    "    result = int_to_char[index]\n",
    "    \n",
    "    # Convert input pattern to character sequence\n",
    "    \n",
    "    seq_in = [int_to_char[value] for value in pattern]\n",
    "    \n",
    "    # Print out predicted characters\n",
    "\n",
    "    sys.stdout.write(result)\n",
    "    \n",
    "    # Append the old pattern \n",
    "    \n",
    "    pattern.append(index)\n",
    "    \n",
    "    # The new input pattern is the new predicted char appended to the last 99 digits of the old input pattern\n",
    "    \n",
    "    pattern = pattern[1:len(pattern)]\n",
    "    \n",
    "    \n",
    "print \"\\nDone.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'i',\n",
       " ' ',\n",
       " 'f',\n",
       " 'a',\n",
       " 's',\n",
       " ' ',\n",
       " 's',\n",
       " 'o',\n",
       " 'o',\n",
       " 'e',\n",
       " 'l',\n",
       " ' ',\n",
       " 't',\n",
       " 'h',\n",
       " 'e',\n",
       " ' ',\n",
       " 's',\n",
       " 'i',\n",
       " 'a',\n",
       " 'r',\n",
       " 'k',\n",
       " ' ',\n",
       " 'o',\n",
       " 'f',\n",
       " ' ',\n",
       " 't',\n",
       " 'h',\n",
       " 'e',\n",
       " ' ',\n",
       " 's',\n",
       " 'i',\n",
       " 'a',\n",
       " 'r',\n",
       " 'k',\n",
       " ' ',\n",
       " 'o',\n",
       " 'f',\n",
       " ' ',\n",
       " 't',\n",
       " 'h',\n",
       " 'e',\n",
       " ' ',\n",
       " 's',\n",
       " 'i',\n",
       " 'a',\n",
       " 'r',\n",
       " 'k',\n",
       " ' ',\n",
       " 'o',\n",
       " 'f',\n",
       " ' ',\n",
       " 't',\n",
       " 'h',\n",
       " 'e',\n",
       " ' ',\n",
       " 's',\n",
       " 'i',\n",
       " 'a',\n",
       " 'r',\n",
       " 'k',\n",
       " ' ',\n",
       " 'o',\n",
       " 'f',\n",
       " ' ',\n",
       " 't',\n",
       " 'h',\n",
       " 'e',\n",
       " ' ',\n",
       " 's',\n",
       " 'i',\n",
       " 'a',\n",
       " 'r',\n",
       " 'k',\n",
       " ' ',\n",
       " 'o',\n",
       " 'f',\n",
       " ' ',\n",
       " 't',\n",
       " 'h',\n",
       " 'e',\n",
       " ' ',\n",
       " 's',\n",
       " 'i',\n",
       " 'a',\n",
       " 'r',\n",
       " 'k',\n",
       " ' ',\n",
       " 'o',\n",
       " 'f',\n",
       " ' ',\n",
       " 't',\n",
       " 'h',\n",
       " 'e',\n",
       " ' ',\n",
       " 's',\n",
       " 'i',\n",
       " 'a',\n",
       " 'r',\n",
       " 'k']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
