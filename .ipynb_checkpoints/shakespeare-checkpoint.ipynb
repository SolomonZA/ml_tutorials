{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib import layers\n",
    "from tensorflow.contrib import rnn\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import my_txtutils as txt\n",
    "import sys\n",
    "\n",
    "tf.set_random_seed(0)\n",
    "tf.reset_default_graph()\n",
    "\n",
    "SEQLEN = 30\n",
    "BATCHSIZE = 20\n",
    "ALPHABETSIZE = txt.ALPHASIZE # 98 characters in vocab being used\n",
    "INTERNALSIZE = 128\n",
    "NLAYERS = 1\n",
    "\n",
    "keep_prob = 0.8\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file shakespeare/2kinghenryvi.txt\n",
      "Loading file shakespeare/asyoulikeit.txt\n",
      "Loading file shakespeare/hamlet.txt\n",
      "Loading file shakespeare/kingjohn.txt\n",
      "Loading file shakespeare/loverscomplaint.txt\n",
      "Loading file shakespeare/merchantofvenice.txt\n",
      "Loading file shakespeare/othello.txt\n",
      "Loading file shakespeare/sonnets.txt\n",
      "Loading file shakespeare/titusandronicus.txt\n",
      "Loading file shakespeare/various.txt\n"
     ]
    }
   ],
   "source": [
    "# Load Shakespeare Data \n",
    "\n",
    "shakedir = \"shakespeare/*.txt\"\n",
    "\n",
    "codetext, valitext, bookranges = txt.read_data_files(shakedir, validation=True)\n",
    "\n",
    "# My_txtuils.py\n",
    "\n",
    "    # uses glob for pathnames\n",
    "    # convert_from_alphabet() - convert to ASCII values\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training text size is 0.93MB with 139.61KB set aside for validation. There will be 1458420 batches per epoch\n"
     ]
    }
   ],
   "source": [
    "# Some statistics\n",
    "\n",
    "epoch_size = len(codetext) // BATCHSIZE * SEQLEN\n",
    "\n",
    "txt.print_data_stats(len(codetext), len(valitext), epoch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholders\n",
    "\n",
    "    # URL: https://learningtensorflow.com/lesson4/\n",
    "    \n",
    "\"\"\"Placeholder: a variable that we will assign data to at a later date. \n",
    "It allows us to create our operations and build our computation\n",
    "graph, without needing the data. \n",
    "\n",
    "In TensorFlow terminology, we then feed data into the graph\n",
    "through these placeholders.\"\"\"\n",
    "\n",
    "# Define placeholders \n",
    "\n",
    "keep_prob_placeholder = tf.placeholder(tf.float32, name = 'keep_prob') # dropout param\n",
    "batchsize = tf.placeholder(tf.int32, name = 'batchsize')\n",
    "\n",
    "# inputs \n",
    "\n",
    "X = tf.placeholder(tf.uint8, [None, None], name = 'X')\n",
    "Xo = tf.one_hot(X, ALPHABETSIZE, 1.0, 0.0)\n",
    "\n",
    "# expected outputs = same sequence shifted by 1 since we are trying\n",
    "# to predict next character\n",
    "\n",
    "Y_ = tf.placeholder(tf.uint8, [None, None], name = 'Y_')\n",
    "Yo_ = tf.one_hot(Y_, ALPHABETSIZE, 1.0, 0.0)\n",
    "\n",
    "# Input state\n",
    "\n",
    "Hin = tf.placeholder(tf.float32, [None, INTERNALSIZE*NLAYERS], name = 'Hin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using NLAYERS of GRU cells, unrolled SEQLEN=30 times\n",
    "# dynamic_rnn infers SEQLEN from the size of the inputs Xo\n",
    "\n",
    "cells = [rnn.GRUCell(INTERNALSIZE) for _ in range(NLAYERS)]\n",
    "\n",
    "# \"naive dropout\" implementaiton\n",
    "dropcells = [rnn.DropoutWrapper(cell, input_keep_prob=keep_prob_placeholder) for cell in cells]\n",
    "\n",
    "multicell = rnn.MultiRNNCell(dropcells, state_is_tuple=False) \n",
    "\n",
    "multicell = rnn.DropoutWrapper(multicell,\n",
    "                               output_keep_prob = keep_prob_placeholder)\n",
    "                                #dropout for the softmax layer\n",
    "\n",
    "Yr, H = tf.nn.dynamic_rnn(multicell, Xo, dtype=tf.float32, initial_state = Hin)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Softmax layer implementation\n",
    "# Flatten the first two dimension of the output\n",
    "    # [BATCHSIZE, SEQLEN, ALPHABETSIZE] => [ BATCHSIZE*SEQLEN, ALPHASIZE]\n",
    "# then apply softmax laye.\n",
    "    # Weights and biases are shared across unrolled time steps\n",
    "    \n",
    "W = tf.Variable(tf.random_normal([INTERNALSIZE, ALPHABETSIZE]))\n",
    "B = tf.Variable(tf.random_normal([ALPHABETSIZE]))\n",
    "\n",
    "Yflat = tf.reshape(Yr, [-1, INTERNALSIZE]) # [BATCHSIZE*SEQLEN, INTERNALSIZE]\n",
    "Ylogits = tf.matmul(Yflat, W) + B # [BATCHSIZE*SEQLEN, ALPHASIZE]\n",
    "\n",
    "Yflat = tf.reshape(Yo_, [-1, ALPHABETSIZE])\n",
    "\n",
    "loss = tf.nn.softmax_cross_entropy_with_logits(logits = Ylogits, labels = Yflat)\n",
    "loss = tf.reshape(loss, [batchsize, -1])\n",
    "\n",
    "Yo = tf.nn.softmax(Ylogits, name = 'Yo')\n",
    "Y = tf.argmax(Yo, 1)\n",
    "Y = tf.reshape(Y, [batchsize, -1], name = \"Y\")\n",
    "\n",
    "train_step = tf.train.AdamOptimizer(0.001).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stats for display\n",
    "\n",
    "seqloss = tf.reduce_mean(loss,1)\n",
    "batchloss = tf.reduce_mean(seqloss)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(Y_, tf.cast(Y, tf.uint8)), tf.float32))\n",
    "\n",
    "# Proress bar\n",
    "\n",
    "DISPLAY_FREQ = 50\n",
    "_50_BATCHES = DISPLAY_FREQ * BATCHSIZE * SEQLEN\n",
    "\n",
    "progress = txt.Progress(DISPLAY_FREQ, size = 111+2,\n",
    "                         msg = \"Training on next\" + str(DISPLAY_FREQ) +\"batches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init\n",
    "\n",
    "istate = np.zeros([BATCHSIZE, INTERNALSIZE * NLAYERS])\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "step = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating some random text...\n",
      "\u0000\u0018\u0000\u0000\u000e\u001f\u000e\u0018\u0000\u0000\u0000\u001b\u0000\u0018<3\u00003\u0000\u0000\u0000\u00060\u0000\u0000\u000e\u0018\u0000\u0000\u00003\u0000\u0000\u000e\u0000\f",
      "\u0018\u0018;\u0014\u0010\u00183\u0000<\u000e\u0000\u0018\u0000\u0018\u0014\u0000\u0000\u0018\u0000\u0000\u0000\u0006\u0000\u0000\u0000\u0000\u0000\u0006\u0018\u00004\u0018<\u0000\u00003\u0000\u0000\u0018\u0000\u001b\u001b\u0000\u0000\u0000#\u0000\u000e\u000e\u0014\u0000\u0000\u0000\u0015\u0000\u0000\u00184\u0018\u0000\u0000\u000e4\u000e77\u0000\u0014\u0000\u001f\u0018\u0000\u0018\u0000\u00003\u00000\u0000#\u00184<7\u00007\u0000\u0000\u0000\u0018\u0018<\u0018\u0000\u0000\u0000\u0018\u0000?A\u0000\u0000\u0000-\u0000\u0000\u0000\u0018\u0000A\u0000\u0018\u00004\u0018\u0000\u0000\u00184\u0000\u0018\u0000\u0000\u0018\u0000\u0000\u0006\u00000#\u0018\u0018\u0000?3\u0000\u0000<\u0006<\u0000\u0018\u0018\u0018?\u0018\u0000\u001b\u0000\u0018;3\u0000\u0000\u001b<\u0000\u0000\u00184\u0000\u0018\u000e\u0000\u0000\u0000\u0018\u000e\u0014\u000e\u0000\u0000\u0000\u00143\u0000\u0000\u0015\u0000\u00000A@\u0000\u0006#\u0018\u00184\u000f0\u0000\u0000\u0000\u0000\u00184\u0000\u0018\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0014\u0000AA\u0000\u0000\u0000\u0000A\u0000\u00180\u00000#4\u0000\u0000\u0018\u0000\u0018\u0000\u0000;-\u0018\u0000AA\u0018\u0000\u000f04\u00000\u0000@\u0018\u0018\u0018\u0000\u001b0;'4@\u00153\u00003\u00003<\u0000\u0018\u0000\u0000\u0000<\u00004\u000e\u0000\u0000\u0006\u0000#\u0000\u0018\u0000<\u0000\u0018\u0006<\u0000\u00060\u0000\u0000\u0000##\u0018\u0000\u0000\u0014\u000044@\u000040\u0018\u0000\u000000\u0000\u0000\u0000\u0000\u0000A\u0000\u0000\u0018\u0018\u0018\u0000\u0018\u0016\u0000?\u0000A\u0018\u0000\u000034\u0000\u00004@0\u0000#\u0000\u0000\u0000\u0018#\u0018\u0018\u0000\u0000\u0000\u00184\u0000\u0000\u0000\u0018\u0000#\u00003<\u000e\u0000\u0018\u0018\u0000<\u0000\u0000\u000e\u0014\u0000\u0000\u0014\u0000\u0000\u0000\u0000\u0014\u00140\u0000\u0000\u0000\u0000\u0018\u0000\u0018\u000e\u0018\u0000\u0000\u0018\u0000\u0010\u0000\u0000#\u0018\u0000\u000e\u0000\u0000\u0000\u0014\u001fA\u000e\u000e\u0000\f",
      "\u00117\u0018;\u0018\u000600<\u0000\u000e\u0018\u0000\u000e\f",
      "\u00007\u0014\u00003\u0018;\u0000\u0000\u0000\u0000\u0000\u0000\u0018\u0000\u0000\u0018\u00000\u000003\u001f33\u00000\u0018\u0018\u0000\u0000\u0018\u0018\u0000\u0018<\u0018\u000e\u0000\u000e\f",
      "\u0000\u0018\u0000\u0018'\u0000\u0015\u0018\u0000\u0018\u0000\u0000A<4\u0018\u0000\u0018\u0000\u0000\u0018\u0000-\u0000@\u0000\u0000\u0000\u0000\u0000?4@@\u0000\u0000\u000034\u0000\u0000\u0000\u0018\f",
      "\u0018\u0000\u000034\u0000\u0000\u0000\u0000\u000e\u0014\u0000\u001f\u0000\u0018\u0000\u0000\u000e\u0000@\u001f\u0000\u0018\u00184\u00000\u0000403\u0018430\u0018'\u0018\u0018\u00003\u0015\u0000<\u0018<\u0018\u0000\u0018'<\u0000\u0000\u000e\u0018\u0018\u00004\u000e\u001f3\u0018\u0000\u0014\u0000\u0000\u0000\u0014\u0018A\u0018\u0000\u0000\u0000\u001b\u000e\u0018\u0000\u0000\u0000\u001f?\u0006\u0018\u0000\u0000\u0000\u0000\u0000\u0018#\u0000\u0000\u0000\u0000\u0000A\u0018\u0000\u0000A\u000f\u0018\u0000\u0000\u0014\u0018\u00180\u00003\u001f4\u0018\u000040\u00183'\u0000\u0015\u0018\u0000\u0018\u0018444*<\u0000\u0000\u0000\u0000#\u0018\u0018\u0018\u0018\u0000\u000e\u0018\u0014\u0018A\u0000'A\u0000\u0000\u0000\u0000\u0018\u0000\u0000?\u0018\u0000\u0018,4\u0018\u0018\u0000\u00004A0\u0000\u0000\u0000\u0000\u0006\u0000\u0018\u0018\u0000\u0018\u0000\u0000\u0000\u00184\u0000\u0000\u0018\u0018\u0010\u0000\u0000\u0018\u0000\u0000#\u00184\u0018\u0000<\u0018\u0000\u0018<B3\u0018\u0018\u0000\u0018?\u001b\u0000\u0000A#\u0018\u0000A\u0006\u0018\u0000\u0018\u0018AA\u0000\u0000\u0018\u0000<<\u0018\u000e\u0018\u000e\u0000\u0000\u0000\u0000\u0000\u0000\u000e\u0000\u0000\u0000\u0000\u000e3\u000e\u0000\u0000\u0000\u0015\u0015\u000e\u0000\u0006\u0000\u0000\u0014\u0000\u0000\u0000\u0000#\u00064\u00004@@\u0018;3\u00004'\u0000\u001f4\u000043\u0018\u00000\u0018\u00000\u0018\u0000\u0000\u001b\u0018\u0000\u0000\u000e\u0000\u0018444\u000003\u0000\u0018<\u0000\u0018\u0018\u00003\u00003<\u0000<B\u001f73\u0018\u0000\u0000\u0000?\u0018<\u0000\u0000-\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000A\u000e\u0000\u001f\u0018\u0018\u0006' \u0000\u0018\u0000A\u0000\u000f0\u000e\u0000\u0006\u0014\u0000\u001f\u0000\u0000\u0000\u0000\u0000\u001f;\f",
      ";\u0015\u00000\u0000\u0000\u0000\u0018A\u0018\u0000A\u001f\u00184\u0000\u00004\u000e\u000e\u0000\u001f\u000e\u0014\u0000\u0018\u0018\u0000\u0018\u0010\u0000\u0000\u0000\u0000?A\u0018\u0000\u0000\u000e\u0014\u0000\u0014\u0000\f",
      "\u00003\u0000\u001b\u000e\u000030\u000e\u001f\u001f\u000e\u0000\u0018\u0000\u0000?\u0000\u0000\u00004\u0000\n",
      "FINISHED GENERATING RANDOM TEXT\n",
      "\n",
      "()\n",
      "0%                                         Training on next50batches                                         100%\n",
      "=================================================================================================================()\n",
      "0%                                         Training on next50batches                                         100%\n",
      "=================================================================================================================()\n",
      "0%                                         Training on next50batches                                         100%\n",
      "=================================================================================================================\n",
      "Generating some random text...\n",
      "7\u0000\u0018A\u0018,-+\u00003270(\u00003\u0000,3%77\u0000%2(\u0000%\u0000-2(\u00003%8-)\u0000;-8-\u0000%\u00003\u000077-\u00008)-2)\u00008,-6\u000073\u00007-\u000086)\u00008\u00008,)\u0000)%-2\u000078,)%\u000039*0)\u0000\u0000%2\u00007)6%-7\u0000-2\u0000%2,)0-+78,)0\u00008,)\u00003%8,7-\u0000163\u0000-7\u000039(32\u0000C\u00002%2\u0000,)20)\u0000%7\u00008)\u00001)63\u0000*6-2)\u00002,\u00003%9(\u0000\u00003\u000070)0\u000033228\u0000738,)%)6\u0000)70\u000039*\u00008\u00003\u00007)\u00008,)\u0000%6\u0000-)63\u0000,7)7\u0000)%-28363\u00007\u0000)26)\u000080\u0000%6397\u0000336(%2\u000088,\u0000)398\u0000,3\u0000132(-7)\u0000,\u0000%2\u00007)%8-)78,)\u0000;6)0\u0000%2+88\u0000%2(\u0000%-(\u0000232)\u00008))6\u0000,\u0000-83\u0000\u000039(\u0000-27)\u00003%00\u0000\u0000-%(\u00008,-7\u0000836\u000013)\u0000-22-8,3\u00003\u000036(\u0000,)%6\u0000;(-')\u0000-8,98)\u00008)\u0000)%)\u0000%67\u0000,%\u000023\u0000,%8-)238\u0000%\u000030\u000082\u00001)-2(\u000017\u0000)%(\u0000-2+\u0000;,)-7\u0000,%7\u0000-%2(\u00007%0\u0000%))\u00001%8\u000033\u0000(%68-2\u000077)83\u0000-+,36%8-)\u00007)7)%2(\u00007\u0000-2+\u0000)\u0000397\u00007%62)8003*\u0000,)\u0000300\u000082)7\u00008)6\u0000-\u00008)\u0000%227-28)\u000030)\u00003\u0000)(6\u00008,)-2(-7\u0000,\u000030(\u0000\u0000,3-)\u0000(8%7-8,%\u0000\u00007\u000033(\u000077\u000083%2(\u00008\u0000,)%0396\u00008,%)\u0000,)28\u0000)%%80\u0000392(\u0000,38\u0000,)%((\u00008,%\u0000%8,\u00002)-2\u0000-8\u0000%3923\u0000%-27(C\u000039-)7)\u0000)83639\u0000%78,\u0000%627\u0000;283000)\u0000,)\u0000)-\u00007\u0000)\u0000)6))7\u0000-2\u00003(%2)%\u0000&)\u00003\u0000397))\u0000%%6\u0000\u000013%)2\u0000%2\u00008\u0000%-)\u0000139\u000060%88\u00003)\u000077\u00003\u000080\u000073%()\u00008,33968\u00008,)%2-2\u0000%2(\u000078\u0000%-(\u0000,)\u0000)\u00007%28\u00007\u00003397)\u00007-28\u0000%)7\u0000-7))\u0000%2(\u0000,%(\u0000-2\u0000390\u000088%)\u00001%227390\u00001)2\u0000-)-\u00008,-6\u0000-2)\u0000%()68%-\u0000%2)637\u00008)\u0000%)\u0000739782\u0000%-6\u000038\u0000-\u0000%-2\u0000%-28,3\u0000\u0000;,)7\u0000;(-)\u00008-2\u0000,)6\u000039()\u00008-\u0000;-2-2\n",
      "FINISHED GENERATING RANDOM TEXT\n",
      "\n",
      "()\n",
      "0%                                         Training on next50batches                                         100%\n",
      "=================================================================================================================()\n",
      "0%                                         Training on next50batches                                         100%\n",
      "=================================================================================================================()\n",
      "0%                                         Training on next50batches                                         100%\n",
      "=================================================================================================================\n",
      "Generating some random text...\n",
      "\u0000\u0000\u000039(2\u0000;30\u0000\u000012\u0000,%\u00001-1\u00008,))\u00001)78,)\u00007)\u0000233\u00001%=\u0000-27300\u000078\u000077\u0000;-398\u0000-2-2(\u0000CC\u0000)7\u00001900\u0000(\u0000)\u000023\u0000;,3\u0000\u00001%2)\u0000239\u0000-7\u00008,=3\u00001-2+-6\u00003*\u0000,-7\u0000%2\u0000-2-8,\u00008,-2\u000017)28\u00008\u0000-2+\u0000,-)\u0000\u0000*)2\u0000332\u0000&)2)7)\u00008%63(\u0000,)%7)\u0000%67\u0000392))\u00007,%2\u0000796\u0000%,90)\u00008-0\u0000-2\u000078,)\u000023;\u0000,%\u0000%031\u00008337\u0000%()\u00003236)\u0000;390(\u000036%2\u0000;-68\u0000136)\u0000,38\u00001\u00002)%(7%62\u0000\u0000,31\u0000&)\u0000,\u0000732\u00007)7,36\u00001-8\u0000-2)\u0000%6)(\u00008-8\u0000\u0000-8\u00001=9\u0000736\u0000;,\u0000-6\u0000%-2)%2(732\u0000132883\u00001-32+\u0000%2)(\u0000%78-\u00001)\u00008%288\u00002%2(\u0000;-8\u00002(\u0000;03\u0000,-\u000078,)))7\u00001)003\u0000-8,)\u0000-23\u00002%',%2+39+,39\u0000(-\u00002\u0000%,\u0000'32\u00001%\u00008-7\u000078)6%\u0000()\u000070)6\u00003128\u0000;-7832')%7\u00008,-\u0000+,-28\u0000%7\u0000-3\u0000,8\u0000=%900(\u0000&\u0000%2\u00008,%77302\u000012(\u00008,)87\u0000-6\u000078,3\u0000*%2\u0000,3\u0000()6392\u0000-78\u0000)2)\u00007\u0000-82\u00008,6\u00001)2(\u0000327\u0000;,39\u0000836\u0000,-2+\u00008,%8)\u00002378\u0000-2+)\u0000,%87\u0000&))\u00007\u0000;)\u00007%0-\u0000,%1)\u0000%6(\u0000,%(\u0000;0-(\u0000;)\u00008,\u0000107\u0000839\u00007%7)%8-7\u00001%8,\u0000\u00007,)7'\u0000,-7\u00008)%8\u0000%6(\u0000;336(C\u0000\u0018,-'\u0000\u0000828\u00008,)\u0000,\u00007)\u00001%2'\u0000%83078CC,%7-)003\u00007,36\u00007)2-0)\u0000,)\u0000238\u000079232\u00008,)8\u0000%3\u0000(-8,)\u0000-27)7\u00001)7,3\u0000\u0000,%6'973\u00008,%6\u0000-8\u0000-0)\u0000;,%8\u0000-,\u00008%\u00002%\u0000-32\u000080)6)\u0000CC\u001b,8\u00007%-)8\u00003\u0000,36\u00008,)%0\u0000,%7)\u0000,%78\u0000\u0000&%-2\u00008,)\u0000-)80\u0000%\u00008,)\u0000-)\u0000,%03\u00001)\u0000%6=-7-8,%8)\u0000-36\u0000132\u00001)\u00007-0\u00008-3\u00001)\u00002)\u00002)\u00008%6)\u000083\u00007\u00001%07\u000086\u00003%()\u0000830-77)C\u0000\u00052(8,)6\u00007%7\u00008,)6\u0000\n",
      "FINISHED GENERATING RANDOM TEXT\n",
      "\n",
      "()\n",
      "0%                                         Training on next50batches                                         100%\n",
      "=================================================================================================================()\n",
      "0%                                         Training on next50batches                                         100%\n",
      "=================================================================================================================()\n",
      "0%                                         Training on next50batches                                         100%\n",
      "=================================================================================================================\n",
      "Generating some random text...\n",
      "\u0000\u0013\u0000;-8\u0000,)6\u00007396(\u00008,397\u00004038,%-8\u0000-3\u00008,)\u00008,)\u0000(7\u0000)*\u0000%2(\u000083)\u0000(6)2\u00008%7\u00007)68\u000039878\u0000=\u00009\u0000'68\u00008\u0000-*\u00001%67\u0000838\u0000-3\u0000,)6=\u0000,)\u0000'%0\u0000738\u0000%6%8\u0000\u00007)%2(\u0000*398\u0000-8\u000032\u0000\u0000,8\u0000)2\u0000,7\u0000-2\u00007\u0000;6))2'%(\u0000&)78)6\u0000C\u0000\u0018,37\u00008,)0\u00007-7\u0000%2)8\u00008)\u0000-38\u0000,-7\u0000%28-2\u00008,)\u0000,%78)6)\u0000\u0000*368\u000083\u00008\u00001)2)78,-8\u000079\u0000%2(\u0000,39\u00008,%8\u0000792\u0000(\u0000363\u00008328\u000073\u00008%6798,\u0000;6)000\u0000%8\u0000,%1\u0000%73\u0000&-8)\u0000;)\u0000831)\u0000\u00008,=\u00000%8\u00007\u000039\u00008,)6)2\u0000,)%/\u00008-)\u00008-77736\u0000*3;\u0000%8\u00008\u0000)\u0000-2\u0000-2+\u00008=96792\u00008,-2+\u0000-3\u0000797832\u0000&0-:)\u0000-6\u00008\u000073\u0000'3\u000078,)6\u0000-2\u00008\u000032\u0000\u00003\u0000\u0000*3\u0000'-2\u00007392(\u0000\u0000-2\u00008\u00008=3927\u000083\u0000,)\u0000,\u000036\u0000-0(\u0000(-2\u0000%2328,90\u000078%6\u000032(\u00008,-28\u000033678C-6)\u0000;)68)\u00007)6\u0000,)%6\u0000()6-8\u0000=3\u000023\u0000,39\u00000-88\u000032\u0000(396\u000036%7\u0000\u0000-7\u0000796)\u0000392+\u0000-2\u000079%2()683978-7\u000078)\u0000832\u00008)\u0000,)\u0000-7\u0000337\u00007,-1)\u0000%003\u00001=\u000032)78,-2\u0000-2\u0000()%=\u0000\u0000;%0(\u0000;32(\u00001%2()7,\u00008)2+\u00008\u0000,)0\u0000%(-)\u0000C\u0000\u00008\u00008-)\u0000(792+)8,36)\u00008,)6\u0000,8)\u00008,)\u0000-2\u00008%2\u0000&9\u00002(\u0000;-87\u00008,)\u0000%2\u00008=\u0000%2+-2)8\u0000\u00007)0%6)78-2(7\u0000%0\u00002\u0000896)6)\u00008,))7,80-+)\u00008,)78-8\u0000)2\u00008\u00008-)\u0000,%8\u0000-7\u0000%2\u0000-2\u00008-0\u0000\u0000-38\u0000&%2\u0000\u0000,377\u0000\u0000*38)6()\u0000\u00008%8\u00008,32\u0000836)6\u00003\u0000()6)\u0000(38\u0000,6\u00001%8))(C\u0000\u0018,-8\u0000,30\u0000&6%7\u0000&)\u0000-2\u0000,\u0000,)\u00008-)\u0000831%(\u00008-1=\u00007)-6\u0000\u0000-2\u00007\u0000%(7\u0000CC\f",
      "\u0005\u0010\u00120\u00008,)\u0000\u0000,%0\u000083\u0000,-+\u00008396-(-\u00008-8\u00007))\u00008,7)\u0000\u0000*-\n",
      "FINISHED GENERATING RANDOM TEXT\n",
      "\n",
      "()\n",
      "0%                                         Training on next50batches                                         100%\n",
      "==================================================================="
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-50f2e91d5432>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHin\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mistate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_prob_placeholder\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatchsize\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mBATCHSIZE\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mostate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# display a short text generated with current weights and biases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/fhl/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/fhl/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/fhl/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/fhl/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/fhl/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "\n",
    "for x, y_, epoch in txt.rnn_minibatch_sequencer(codetext, BATCHSIZE,\n",
    "                                               SEQLEN, nb_epochs =2):\n",
    "    \n",
    "    # train on one minibatch\n",
    "    \n",
    "    feed_dict = {X: x, Y_: y_, Hin: istate, keep_prob_placeholder: keep_prob, batchsize: BATCHSIZE}\n",
    "\n",
    "    _, y, ostate = sess.run([train_step, Y, H], feed_dict=feed_dict)\n",
    "    \n",
    "    # display a short text generated with current weights and biases\n",
    "    \n",
    "    if step // 3 % _50_BATCHES == 0:\n",
    "        print\n",
    "        print \"Generating some random text...\"\n",
    "        \n",
    "        ry = np.array([[txt.convert_from_alphabet(ord(\"K\"))]])\n",
    "        rh = np.zeros([1, INTERNALSIZE*NLAYERS])\n",
    "        \n",
    "        for k in range(1000):\n",
    "            ryo, rh = sess.run([Yo, H], feed_dict = {X: ry,\n",
    "                                                     keep_prob_placeholder: 1.0,\n",
    "                                                    Hin: rh, batchsize: 1})\n",
    "            \n",
    "            rc = txt.sample_from_probabilities(ryo, topn=10 if epoch <= 1 else 2)\n",
    "            \n",
    "            sys.stdout.write(chr(txt.convert_to_alphabet(rc)))\n",
    "            \n",
    "            ry = np.array([[rc]])\n",
    "            \n",
    "        print\n",
    "        print \"FINISHED GENERATING RANDOM TEXT\"\n",
    "        print\n",
    "        \n",
    "    # display progress bar\n",
    "    progress.step(reset = step % _50_BATCHES == 0)\n",
    "    \n",
    "    # loop state around\n",
    "    istate = ostate\n",
    "    step += BATCHSIZE * SEQLEN\n",
    "    \n",
    "print \n",
    "print \"----FINISHED TRAINING\"\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
